log4j.rootLogger=off,stdout,rolling1,rolling2

log4j.appender.stdout = org.apache.log4j.ConsoleAppender
log4j.appender.stdout.Threshold=off
log4j.appender.stdout.Target = System.out
log4j.appender.stdout.layout = org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm} %5p %t %c{2}:%L - %m%n

log4j.appender.rolling1=org.apache.log4j.RollingFileAppender
log4j.appender.rolling1.Threshold=off
log4j.appender.rolling1.layout=org.apache.log4j.PatternLayout
log4j.appender.rolling1.layout.conversionPattern=%-d{yyyy-MM-dd HH:mm:ss} %5p %t %c{2}:%L - %m%n
log4j.appender.rolling1.maxFileSize=100MB
log4j.appender.rolling1.maxBackupIndex=5
#log4j.appender.rolling1.file=${spark.yarn.app.container.log.dir}/stdout
log4j.appender.rolling1.file=spark-core/log/cdn-error.log
log4j.appender.rolling1.encoding=UTF-8

log4j.appender.rolling2=org.apache.log4j.RollingFileAppender
log4j.appender.rolling2.Threshold=off
log4j.appender.rolling2.layout=org.apache.log4j.PatternLayout
log4j.appender.rolling2.layout.conversionPattern=%-d{yyyy-MM-dd HH:mm:ss} %5p %t %c{2}:%L - %m%n
log4j.appender.rolling2.maxFileSize=100MB
log4j.appender.rolling2.maxBackupIndex=5
#log4j.appender.rolling.file=${spark.yarn.app.container.log.dir}/stdout
log4j.appender.rolling2.file=h2-demo/log/by-sql.log
log4j.appender.rolling2.encoding=UTF-8

# 以下照搬原文件配置，主要是防止一些Spark引用的第三方组件日志输出过多
log4j.logger.scalikejdbc=off
